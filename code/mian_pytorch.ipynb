{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "signal = []\n",
    "label = []\n",
    "\n",
    "with open('C:\\\\Users\\\\yurui\\\\Desktop\\\\item\\\\heart\\\\data\\\\train.csv','r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for line in reader:\n",
    "        signal.append([float(num) for num in line['heartbeat_signals'].split(',')])\n",
    "        label.append(int(float(line['label'])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda:1\n",
      "Setting up a new session...\n",
      "Data Loading Finished\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from DataAdapter import *\n",
    "import torch.utils.data as Data\n",
    "import visdom\n",
    "from filter import filter\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "#设置训练显卡\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "signal_filt = []\n",
    "train_split = 0.8\n",
    "valid_split = 0.1\n",
    "\n",
    "for sig in signal:\n",
    "    signal_filt.append(filter(sig))\n",
    "\n",
    "dataset = DataAdapter(signal_filt,label)\n",
    "train_size = int(len(signal) * train_split) - int(len(signal) * valid_split)\n",
    "valid_size = int(len(signal) * valid_split)\n",
    "test_size = len(signal_filt) - train_size - valid_size\n",
    "train_dataset,valid_dataset,test_dataset = Data.random_split(dataset,[train_size,valid_size,test_size])\n",
    "\n",
    "train_loader = Data.DataLoader(train_dataset,batch_size = batch_size,shuffle = True,num_workers = 0)\n",
    "valid_loader = Data.DataLoader(valid_dataset,batch_size = batch_size,shuffle = True,num_workers = 0)\n",
    "test_loader = Data.DataLoader(test_dataset,batch_size = batch_size,shuffle = False,num_workers = 0)\n",
    "\n",
    "print('Data Loading Finished')\n",
    "\n",
    "#训练可视化\n",
    "vis = visdom.Visdom(port = 8007) #python -m visdom.server -p 8007  建立visdom本地虚拟服务器的代码 cmd下运行\n",
    "loss_curve = vis.line(\n",
    "    X = np.array( [0] ),\n",
    "    Y = np.array( [[0,0]] ),\n",
    "    opts = dict(\n",
    "           xlabel='epoch',\n",
    "           ylabel='train_loss',\n",
    "           legend=['train_loss','valid_loss'])\n",
    ")\n",
    "acc_curve = vis.line(\n",
    "    X = np.array( [0] ),\n",
    "    Y = np.array( [[0,0]] ),\n",
    "    opts = dict(\n",
    "           xlabel='epoch',\n",
    "           ylabel='acc',\n",
    "           legend=['train_acc','valid_acc'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels = 1,out_channels = 32,kernel_size = 10,stride = 1,padding = 0)\n",
    "        self.conv2 = nn.Conv1d(32,64,10,1)\n",
    "        self.conv3 = nn.Conv1d(64,128,1,1)\n",
    "        self.conv4 = nn.Conv1d(128,256,1,1)\n",
    "        self.maxpool = nn.MaxPool1d(4)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear_unit = nn.Sequential(\n",
    "            nn.Linear(2816,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,4),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.view(x.size(0),1,x.size(1))\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.linear_unit(x)\n",
    "        return x\n",
    "\n",
    "# x = torch.rand(1,205)\n",
    "# model = CNN()\n",
    "# y = model.forward(x)\n",
    "# print(y.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " - Train_loss: 0.75108 - Train_acc: 0.99260 - Val_loss: 0.75609 - Val_acc: 0.987441 - T_Time: 8.483\n",
      "- Epoch: 127 - Train_loss: 0.75128 - Train_acc: 0.99240 - Val_loss: 0.75470 - Val_acc: 0.989122 - T_Time: 8.499\n",
      "- Epoch: 128 - Train_loss: 0.75131 - Train_acc: 0.99235 - Val_loss: 0.75474 - Val_acc: 0.988825 - T_Time: 8.508\n",
      "- Epoch: 129 - Train_loss: 0.75101 - Train_acc: 0.99274 - Val_loss: 0.75477 - Val_acc: 0.988627 - T_Time: 8.586\n",
      "- Epoch: 130 - Train_loss: 0.75108 - Train_acc: 0.99263 - Val_loss: 0.75557 - Val_acc: 0.987935 - T_Time: 8.483\n",
      "- Epoch: 131 - Train_loss: 0.75128 - Train_acc: 0.99243 - Val_loss: 0.75597 - Val_acc: 0.987540 - T_Time: 8.427\n",
      "- Epoch: 132 - Train_loss: 0.75124 - Train_acc: 0.99244 - Val_loss: 0.75569 - Val_acc: 0.987737 - T_Time: 8.462\n",
      "- Epoch: 133 - Train_loss: 0.75089 - Train_acc: 0.99279 - Val_loss: 0.75471 - Val_acc: 0.988924 - T_Time: 8.438\n",
      "- Epoch: 134 - Train_loss: 0.75077 - Train_acc: 0.99290 - Val_loss: 0.75436 - Val_acc: 0.989221 - T_Time: 8.457\n",
      "Find better model in Epoch 134, saving model.\n",
      "- Epoch: 135 - Train_loss: 0.75109 - Train_acc: 0.99260 - Val_loss: 0.75450 - Val_acc: 0.989122 - T_Time: 8.630\n",
      "- Epoch: 136 - Train_loss: 0.75089 - Train_acc: 0.99280 - Val_loss: 0.75612 - Val_acc: 0.987638 - T_Time: 8.605\n",
      "- Epoch: 137 - Train_loss: 0.75117 - Train_acc: 0.99249 - Val_loss: 0.75524 - Val_acc: 0.988232 - T_Time: 8.577\n",
      "- Epoch: 138 - Train_loss: 0.75105 - Train_acc: 0.99261 - Val_loss: 0.75488 - Val_acc: 0.988528 - T_Time: 8.587\n",
      "- Epoch: 139 - Train_loss: 0.75071 - Train_acc: 0.99295 - Val_loss: 0.75701 - Val_acc: 0.985759 - T_Time: 8.466\n",
      "- Epoch: 140 - Train_loss: 0.75085 - Train_acc: 0.99282 - Val_loss: 0.75450 - Val_acc: 0.989419 - T_Time: 8.594\n",
      "- Epoch: 141 - Train_loss: 0.75076 - Train_acc: 0.99293 - Val_loss: 0.75464 - Val_acc: 0.988825 - T_Time: 8.495\n",
      "- Epoch: 142 - Train_loss: 0.75084 - Train_acc: 0.99287 - Val_loss: 0.75507 - Val_acc: 0.988528 - T_Time: 8.528\n",
      "- Epoch: 143 - Train_loss: 0.75102 - Train_acc: 0.99270 - Val_loss: 0.75673 - Val_acc: 0.986847 - T_Time: 8.521\n",
      "- Epoch: 144 - Train_loss: 0.75096 - Train_acc: 0.99277 - Val_loss: 0.75543 - Val_acc: 0.988133 - T_Time: 8.649\n",
      "- Epoch: 145 - Train_loss: 0.75083 - Train_acc: 0.99284 - Val_loss: 0.75535 - Val_acc: 0.988331 - T_Time: 8.595\n",
      "- Epoch: 146 - Train_loss: 0.75118 - Train_acc: 0.99240 - Val_loss: 0.75606 - Val_acc: 0.987441 - T_Time: 8.437\n",
      "- Epoch: 147 - Train_loss: 0.75088 - Train_acc: 0.99277 - Val_loss: 0.75623 - Val_acc: 0.987737 - T_Time: 8.493\n",
      "- Epoch: 148 - Train_loss: 0.75111 - Train_acc: 0.99263 - Val_loss: 0.75452 - Val_acc: 0.988825 - T_Time: 8.415\n",
      "- Epoch: 149 - Train_loss: 0.75054 - Train_acc: 0.99314 - Val_loss: 0.75597 - Val_acc: 0.987540 - T_Time: 8.599\n",
      "- Epoch: 150 - Train_loss: 0.75067 - Train_acc: 0.99300 - Val_loss: 0.75451 - Val_acc: 0.989122 - T_Time: 8.590\n",
      "- Epoch: 151 - Train_loss: 0.75067 - Train_acc: 0.99296 - Val_loss: 0.75468 - Val_acc: 0.989221 - T_Time: 8.528\n",
      "- Epoch: 152 - Train_loss: 0.75076 - Train_acc: 0.99292 - Val_loss: 0.75530 - Val_acc: 0.988034 - T_Time: 8.569\n",
      "- Epoch: 153 - Train_loss: 0.75057 - Train_acc: 0.99309 - Val_loss: 0.75530 - Val_acc: 0.988430 - T_Time: 8.493\n",
      "- Epoch: 154 - Train_loss: 0.75088 - Train_acc: 0.99283 - Val_loss: 0.75506 - Val_acc: 0.988627 - T_Time: 8.610\n",
      "- Epoch: 155 - Train_loss: 0.75085 - Train_acc: 0.99290 - Val_loss: 0.75517 - Val_acc: 0.988331 - T_Time: 8.493\n",
      "- Epoch: 156 - Train_loss: 0.75069 - Train_acc: 0.99297 - Val_loss: 0.75469 - Val_acc: 0.989122 - T_Time: 8.520\n",
      "- Epoch: 157 - Train_loss: 0.75059 - Train_acc: 0.99309 - Val_loss: 0.75510 - Val_acc: 0.988430 - T_Time: 8.537\n",
      "- Epoch: 158 - Train_loss: 0.75037 - Train_acc: 0.99331 - Val_loss: 0.75544 - Val_acc: 0.988331 - T_Time: 8.538\n",
      "- Epoch: 159 - Train_loss: 0.75073 - Train_acc: 0.99296 - Val_loss: 0.75584 - Val_acc: 0.987737 - T_Time: 8.516\n",
      "- Epoch: 160 - Train_loss: 0.75079 - Train_acc: 0.99286 - Val_loss: 0.75520 - Val_acc: 0.988331 - T_Time: 8.450\n",
      "- Epoch: 161 - Train_loss: 0.75055 - Train_acc: 0.99312 - Val_loss: 0.75524 - Val_acc: 0.988331 - T_Time: 8.514\n",
      "- Epoch: 162 - Train_loss: 0.75057 - Train_acc: 0.99310 - Val_loss: 0.75557 - Val_acc: 0.987737 - T_Time: 8.563\n",
      "- Epoch: 163 - Train_loss: 0.75057 - Train_acc: 0.99310 - Val_loss: 0.75590 - Val_acc: 0.987540 - T_Time: 8.542\n",
      "- Epoch: 164 - Train_loss: 0.75042 - Train_acc: 0.99323 - Val_loss: 0.75511 - Val_acc: 0.988331 - T_Time: 8.557\n",
      "- Epoch: 165 - Train_loss: 0.75055 - Train_acc: 0.99312 - Val_loss: 0.75612 - Val_acc: 0.987243 - T_Time: 8.545\n",
      "- Epoch: 166 - Train_loss: 0.75043 - Train_acc: 0.99322 - Val_loss: 0.75547 - Val_acc: 0.988034 - T_Time: 8.519\n",
      "- Epoch: 167 - Train_loss: 0.75071 - Train_acc: 0.99294 - Val_loss: 0.75662 - Val_acc: 0.986847 - T_Time: 8.486\n",
      "- Epoch: 168 - Train_loss: 0.75057 - Train_acc: 0.99313 - Val_loss: 0.75528 - Val_acc: 0.988133 - T_Time: 8.437\n",
      "- Epoch: 169 - Train_loss: 0.75024 - Train_acc: 0.99343 - Val_loss: 0.75539 - Val_acc: 0.988034 - T_Time: 8.572\n",
      "- Epoch: 170 - Train_loss: 0.75063 - Train_acc: 0.99310 - Val_loss: 0.75570 - Val_acc: 0.987737 - T_Time: 8.519\n",
      "- Epoch: 171 - Train_loss: 0.75067 - Train_acc: 0.99298 - Val_loss: 0.75433 - Val_acc: 0.989122 - T_Time: 8.524\n",
      "Find better model in Epoch 171, saving model.\n",
      "- Epoch: 172 - Train_loss: 0.75045 - Train_acc: 0.99323 - Val_loss: 0.75579 - Val_acc: 0.987540 - T_Time: 8.501\n",
      "- Epoch: 173 - Train_loss: 0.75039 - Train_acc: 0.99326 - Val_loss: 0.75463 - Val_acc: 0.989023 - T_Time: 8.590\n",
      "- Epoch: 174 - Train_loss: 0.75060 - Train_acc: 0.99304 - Val_loss: 0.75475 - Val_acc: 0.988726 - T_Time: 8.533\n",
      "- Epoch: 175 - Train_loss: 0.75035 - Train_acc: 0.99333 - Val_loss: 0.75540 - Val_acc: 0.988034 - T_Time: 8.521\n",
      "- Epoch: 176 - Train_loss: 0.75032 - Train_acc: 0.99337 - Val_loss: 0.75630 - Val_acc: 0.986946 - T_Time: 8.432\n",
      "- Epoch: 177 - Train_loss: 0.75035 - Train_acc: 0.99331 - Val_loss: 0.75533 - Val_acc: 0.988232 - T_Time: 8.527\n",
      "- Epoch: 178 - Train_loss: 0.75058 - Train_acc: 0.99308 - Val_loss: 0.75519 - Val_acc: 0.988627 - T_Time: 8.537\n",
      "- Epoch: 179 - Train_loss: 0.75049 - Train_acc: 0.99319 - Val_loss: 0.75521 - Val_acc: 0.988430 - T_Time: 8.500\n",
      "- Epoch: 180 - Train_loss: 0.75028 - Train_acc: 0.99343 - Val_loss: 0.75572 - Val_acc: 0.987935 - T_Time: 8.509\n",
      "- Epoch: 181 - Train_loss: 0.75034 - Train_acc: 0.99334 - Val_loss: 0.75551 - Val_acc: 0.987935 - T_Time: 8.704\n",
      "- Epoch: 182 - Train_loss: 0.75043 - Train_acc: 0.99323 - Val_loss: 0.75429 - Val_acc: 0.989419 - T_Time: 8.529\n",
      "Find better model in Epoch 182, saving model.\n",
      "- Epoch: 183 - Train_loss: 0.75009 - Train_acc: 0.99354 - Val_loss: 0.75454 - Val_acc: 0.988825 - T_Time: 8.563\n",
      "- Epoch: 184 - Train_loss: 0.75025 - Train_acc: 0.99343 - Val_loss: 0.75507 - Val_acc: 0.988430 - T_Time: 8.534\n",
      "- Epoch: 185 - Train_loss: 0.75021 - Train_acc: 0.99347 - Val_loss: 0.75576 - Val_acc: 0.987737 - T_Time: 8.559\n",
      "- Epoch: 186 - Train_loss: 0.75014 - Train_acc: 0.99356 - Val_loss: 0.75524 - Val_acc: 0.988034 - T_Time: 8.562\n",
      "- Epoch: 187 - Train_loss: 0.75033 - Train_acc: 0.99337 - Val_loss: 0.75509 - Val_acc: 0.988331 - T_Time: 8.523\n",
      "- Epoch: 188 - Train_loss: 0.75025 - Train_acc: 0.99344 - Val_loss: 0.75416 - Val_acc: 0.989517 - T_Time: 8.511\n",
      "Find better model in Epoch 188, saving model.\n",
      "- Epoch: 189 - Train_loss: 0.75018 - Train_acc: 0.99347 - Val_loss: 0.75512 - Val_acc: 0.988627 - T_Time: 8.542\n",
      "- Epoch: 190 - Train_loss: 0.75037 - Train_acc: 0.99330 - Val_loss: 0.75554 - Val_acc: 0.988034 - T_Time: 8.436\n",
      "- Epoch: 191 - Train_loss: 0.75040 - Train_acc: 0.99323 - Val_loss: 0.75496 - Val_acc: 0.988528 - T_Time: 8.441\n",
      "- Epoch: 192 - Train_loss: 0.75005 - Train_acc: 0.99362 - Val_loss: 0.75395 - Val_acc: 0.989715 - T_Time: 8.489\n",
      "Find better model in Epoch 192, saving model.\n",
      "- Epoch: 193 - Train_loss: 0.75008 - Train_acc: 0.99353 - Val_loss: 0.75517 - Val_acc: 0.988430 - T_Time: 8.528\n",
      "- Epoch: 194 - Train_loss: 0.75031 - Train_acc: 0.99336 - Val_loss: 0.75517 - Val_acc: 0.988430 - T_Time: 8.511\n",
      "- Epoch: 195 - Train_loss: 0.75031 - Train_acc: 0.99340 - Val_loss: 0.75493 - Val_acc: 0.988528 - T_Time: 8.413\n",
      "- Epoch: 196 - Train_loss: 0.75028 - Train_acc: 0.99337 - Val_loss: 0.75382 - Val_acc: 0.989715 - T_Time: 8.492\n",
      "Find better model in Epoch 196, saving model.\n",
      "- Epoch: 197 - Train_loss: 0.75023 - Train_acc: 0.99342 - Val_loss: 0.75575 - Val_acc: 0.987935 - T_Time: 8.595\n",
      "- Epoch: 198 - Train_loss: 0.75012 - Train_acc: 0.99354 - Val_loss: 0.75406 - Val_acc: 0.989320 - T_Time: 8.505\n",
      "- Epoch: 199 - Train_loss: 0.75012 - Train_acc: 0.99354 - Val_loss: 0.75390 - Val_acc: 0.989517 - T_Time: 8.402\n",
      "- Epoch: 200 - Train_loss: 0.75025 - Train_acc: 0.99341 - Val_loss: 0.75405 - Val_acc: 0.989715 - T_Time: 8.474\n",
      "- Epoch: 201 - Train_loss: 0.75011 - Train_acc: 0.99357 - Val_loss: 0.75564 - Val_acc: 0.987638 - T_Time: 8.505\n",
      "- Epoch: 202 - Train_loss: 0.75049 - Train_acc: 0.99321 - Val_loss: 0.75462 - Val_acc: 0.989023 - T_Time: 8.486\n",
      "- Epoch: 203 - Train_loss: 0.75012 - Train_acc: 0.99354 - Val_loss: 0.75403 - Val_acc: 0.989419 - T_Time: 8.577\n",
      "- Epoch: 204 - Train_loss: 0.75009 - Train_acc: 0.99362 - Val_loss: 0.75463 - Val_acc: 0.988924 - T_Time: 8.551\n",
      "- Epoch: 205 - Train_loss: 0.75008 - Train_acc: 0.99359 - Val_loss: 0.75441 - Val_acc: 0.988924 - T_Time: 8.575\n",
      "- Epoch: 206 - Train_loss: 0.75002 - Train_acc: 0.99366 - Val_loss: 0.75508 - Val_acc: 0.988430 - T_Time: 8.487\n",
      "- Epoch: 207 - Train_loss: 0.75011 - Train_acc: 0.99347 - Val_loss: 0.75446 - Val_acc: 0.988924 - T_Time: 8.452\n",
      "- Epoch: 208 - Train_loss: 0.75015 - Train_acc: 0.99353 - Val_loss: 0.75380 - Val_acc: 0.990012 - T_Time: 8.514\n",
      "Find better model in Epoch 208, saving model.\n",
      "- Epoch: 209 - Train_loss: 0.75021 - Train_acc: 0.99346 - Val_loss: 0.75448 - Val_acc: 0.989122 - T_Time: 8.620\n",
      "- Epoch: 210 - Train_loss: 0.75018 - Train_acc: 0.99346 - Val_loss: 0.75484 - Val_acc: 0.988825 - T_Time: 8.524\n",
      "- Epoch: 211 - Train_loss: 0.75028 - Train_acc: 0.99339 - Val_loss: 0.75470 - Val_acc: 0.988924 - T_Time: 8.490\n",
      "- Epoch: 212 - Train_loss: 0.75014 - Train_acc: 0.99349 - Val_loss: 0.75557 - Val_acc: 0.987836 - T_Time: 8.691\n",
      "- Epoch: 213 - Train_loss: 0.75007 - Train_acc: 0.99359 - Val_loss: 0.75484 - Val_acc: 0.988627 - T_Time: 8.505\n",
      "- Epoch: 214 - Train_loss: 0.75007 - Train_acc: 0.99359 - Val_loss: 0.75411 - Val_acc: 0.989320 - T_Time: 8.494\n",
      "- Epoch: 215 - Train_loss: 0.75013 - Train_acc: 0.99350 - Val_loss: 0.75470 - Val_acc: 0.988726 - T_Time: 8.562\n",
      "- Epoch: 216 - Train_loss: 0.75024 - Train_acc: 0.99339 - Val_loss: 0.75502 - Val_acc: 0.988430 - T_Time: 8.555\n",
      "- Epoch: 217 - Train_loss: 0.75022 - Train_acc: 0.99337 - Val_loss: 0.75539 - Val_acc: 0.988133 - T_Time: 8.504\n",
      "- Epoch: 218 - Train_loss: 0.75001 - Train_acc: 0.99364 - Val_loss: 0.75440 - Val_acc: 0.989023 - T_Time: 8.513\n",
      "- Epoch: 219 - Train_loss: 0.75006 - Train_acc: 0.99359 - Val_loss: 0.75407 - Val_acc: 0.989616 - T_Time: 8.417\n",
      "- Epoch: 220 - Train_loss: 0.75019 - Train_acc: 0.99347 - Val_loss: 0.75530 - Val_acc: 0.988232 - T_Time: 8.434\n",
      "- Epoch: 221 - Train_loss: 0.75012 - Train_acc: 0.99354 - Val_loss: 0.75390 - Val_acc: 0.989616 - T_Time: 8.481\n",
      "- Epoch: 222 - Train_loss: 0.74985 - Train_acc: 0.99381 - Val_loss: 0.75356 - Val_acc: 0.990012 - T_Time: 8.703\n",
      "Find better model in Epoch 222, saving model.\n",
      "- Epoch: 223 - Train_loss: 0.74997 - Train_acc: 0.99370 - Val_loss: 0.75430 - Val_acc: 0.989517 - T_Time: 8.488\n",
      "- Epoch: 224 - Train_loss: 0.75010 - Train_acc: 0.99356 - Val_loss: 0.75414 - Val_acc: 0.989122 - T_Time: 8.449\n",
      "- Epoch: 225 - Train_loss: 0.75003 - Train_acc: 0.99363 - Val_loss: 0.75363 - Val_acc: 0.989913 - T_Time: 8.545\n",
      "- Epoch: 226 - Train_loss: 0.75016 - Train_acc: 0.99354 - Val_loss: 0.75397 - Val_acc: 0.989715 - T_Time: 8.434\n",
      "- Epoch: 227 - Train_loss: 0.75019 - Train_acc: 0.99350 - Val_loss: 0.75451 - Val_acc: 0.989023 - T_Time: 8.412\n",
      "- Epoch: 228 - Train_loss: 0.75017 - Train_acc: 0.99353 - Val_loss: 0.75445 - Val_acc: 0.989221 - T_Time: 8.480\n",
      "- Epoch: 229 - Train_loss: 0.74999 - Train_acc: 0.99363 - Val_loss: 0.75398 - Val_acc: 0.989814 - T_Time: 8.463\n",
      "- Epoch: 230 - Train_loss: 0.74987 - Train_acc: 0.99377 - Val_loss: 0.75416 - Val_acc: 0.989517 - T_Time: 8.465\n",
      "- Epoch: 231 - Train_loss: 0.74989 - Train_acc: 0.99376 - Val_loss: 0.75580 - Val_acc: 0.987441 - T_Time: 8.532\n",
      "- Epoch: 232 - Train_loss: 0.75005 - Train_acc: 0.99360 - Val_loss: 0.75525 - Val_acc: 0.988331 - T_Time: 8.517\n",
      "- Epoch: 233 - Train_loss: 0.75003 - Train_acc: 0.99360 - Val_loss: 0.75498 - Val_acc: 0.988627 - T_Time: 8.414\n",
      "- Epoch: 234 - Train_loss: 0.74996 - Train_acc: 0.99374 - Val_loss: 0.75549 - Val_acc: 0.987737 - T_Time: 8.405\n",
      "- Epoch: 235 - Train_loss: 0.74992 - Train_acc: 0.99371 - Val_loss: 0.75445 - Val_acc: 0.989023 - T_Time: 8.464\n",
      "- Epoch: 236 - Train_loss: 0.75022 - Train_acc: 0.99343 - Val_loss: 0.75454 - Val_acc: 0.988924 - T_Time: 8.519\n",
      "- Epoch: 237 - Train_loss: 0.74996 - Train_acc: 0.99374 - Val_loss: 0.75408 - Val_acc: 0.989517 - T_Time: 8.566\n",
      "- Epoch: 238 - Train_loss: 0.74986 - Train_acc: 0.99381 - Val_loss: 0.75422 - Val_acc: 0.989221 - T_Time: 8.493\n",
      "- Epoch: 239 - Train_loss: 0.74999 - Train_acc: 0.99367 - Val_loss: 0.75540 - Val_acc: 0.988034 - T_Time: 8.555\n",
      "- Epoch: 240 - Train_loss: 0.75014 - Train_acc: 0.99350 - Val_loss: 0.75397 - Val_acc: 0.989814 - T_Time: 8.506\n",
      "- Epoch: 241 - Train_loss: 0.74998 - Train_acc: 0.99369 - Val_loss: 0.75473 - Val_acc: 0.988924 - T_Time: 8.493\n",
      "- Epoch: 242 - Train_loss: 0.74998 - Train_acc: 0.99369 - Val_loss: 0.75616 - Val_acc: 0.987540 - T_Time: 8.520\n",
      "- Epoch: 243 - Train_loss: 0.74989 - Train_acc: 0.99374 - Val_loss: 0.75479 - Val_acc: 0.988825 - T_Time: 8.491\n",
      "- Epoch: 244 - Train_loss: 0.74988 - Train_acc: 0.99376 - Val_loss: 0.75401 - Val_acc: 0.989221 - T_Time: 8.513\n",
      "- Epoch: 245 - Train_loss: 0.74987 - Train_acc: 0.99380 - Val_loss: 0.75453 - Val_acc: 0.989023 - T_Time: 8.521\n",
      "- Epoch: 246 - Train_loss: 0.75028 - Train_acc: 0.99334 - Val_loss: 0.75442 - Val_acc: 0.989122 - T_Time: 8.476\n",
      "- Epoch: 247 - Train_loss: 0.74997 - Train_acc: 0.99370 - Val_loss: 0.75359 - Val_acc: 0.990012 - T_Time: 8.478\n",
      "- Epoch: 248 - Train_loss: 0.74985 - Train_acc: 0.99382 - Val_loss: 0.75353 - Val_acc: 0.989913 - T_Time: 8.538\n",
      "Find better model in Epoch 248, saving model.\n",
      "- Epoch: 249 - Train_loss: 0.75002 - Train_acc: 0.99364 - Val_loss: 0.75469 - Val_acc: 0.988825 - T_Time: 8.554\n",
      "- Epoch: 250 - Train_loss: 0.74996 - Train_acc: 0.99369 - Val_loss: 0.75442 - Val_acc: 0.989221 - T_Time: 8.499\n",
      "- Epoch: 251 - Train_loss: 0.74983 - Train_acc: 0.99384 - Val_loss: 0.75433 - Val_acc: 0.989419 - T_Time: 8.490\n",
      "- Epoch: 252 - Train_loss: 0.74997 - Train_acc: 0.99373 - Val_loss: 0.75472 - Val_acc: 0.988627 - T_Time: 8.919\n",
      "- Epoch: 253 - Train_loss: 0.75021 - Train_acc: 0.99349 - Val_loss: 0.75426 - Val_acc: 0.989320 - T_Time: 8.504\n",
      "- Epoch: 254 - Train_loss: 0.74985 - Train_acc: 0.99380 - Val_loss: 0.75482 - Val_acc: 0.988825 - T_Time: 8.509\n",
      "- Epoch: 255 - Train_loss: 0.75001 - Train_acc: 0.99366 - Val_loss: 0.75528 - Val_acc: 0.988232 - T_Time: 8.546\n",
      "- Epoch: 256 - Train_loss: 0.74986 - Train_acc: 0.99383 - Val_loss: 0.75490 - Val_acc: 0.988627 - T_Time: 8.586\n",
      "- Epoch: 257 - Train_loss: 0.74984 - Train_acc: 0.99384 - Val_loss: 0.75501 - Val_acc: 0.988528 - T_Time: 8.432\n",
      "- Epoch: 258 - Train_loss: 0.74996 - Train_acc: 0.99370 - Val_loss: 0.75431 - Val_acc: 0.989023 - T_Time: 8.532\n",
      "- Epoch: 259 - Train_loss: 0.74984 - Train_acc: 0.99382 - Val_loss: 0.75542 - Val_acc: 0.988331 - T_Time: 8.426\n",
      "- Epoch: 260 - Train_loss: 0.74984 - Train_acc: 0.99383 - Val_loss: 0.75410 - Val_acc: 0.989616 - T_Time: 8.485\n",
      "- Epoch: 261 - Train_loss: 0.74990 - Train_acc: 0.99375 - Val_loss: 0.75349 - Val_acc: 0.990210 - T_Time: 8.476\n",
      "Find better model in Epoch 261, saving model.\n",
      "- Epoch: 262 - Train_loss: 0.74984 - Train_acc: 0.99384 - Val_loss: 0.75417 - Val_acc: 0.989320 - T_Time: 8.436\n",
      "- Epoch: 263 - Train_loss: 0.74982 - Train_acc: 0.99383 - Val_loss: 0.75524 - Val_acc: 0.988331 - T_Time: 8.459\n",
      "- Epoch: 264 - Train_loss: 0.74988 - Train_acc: 0.99377 - Val_loss: 0.75382 - Val_acc: 0.989814 - T_Time: 8.462\n",
      "- Epoch: 265 - Train_loss: 0.74971 - Train_acc: 0.99395 - Val_loss: 0.75502 - Val_acc: 0.988430 - T_Time: 8.487\n",
      "- Epoch: 266 - Train_loss: 0.74986 - Train_acc: 0.99377 - Val_loss: 0.75479 - Val_acc: 0.988627 - T_Time: 8.516\n",
      "- Epoch: 267 - Train_loss: 0.74991 - Train_acc: 0.99373 - Val_loss: 0.75377 - Val_acc: 0.989913 - T_Time: 9.547\n",
      "- Epoch: 268 - Train_loss: 0.74981 - Train_acc: 0.99386 - Val_loss: 0.75396 - Val_acc: 0.989517 - T_Time: 8.494\n",
      "- Epoch: 269 - Train_loss: 0.75018 - Train_acc: 0.99343 - Val_loss: 0.75388 - Val_acc: 0.989715 - T_Time: 8.486\n",
      "- Epoch: 270 - Train_loss: 0.75002 - Train_acc: 0.99360 - Val_loss: 0.75458 - Val_acc: 0.988924 - T_Time: 8.485\n",
      "- Epoch: 271 - Train_loss: 0.74998 - Train_acc: 0.99364 - Val_loss: 0.75437 - Val_acc: 0.989023 - T_Time: 8.509\n",
      "- Epoch: 272 - Train_loss: 0.74973 - Train_acc: 0.99389 - Val_loss: 0.75351 - Val_acc: 0.990012 - T_Time: 8.511\n",
      "- Epoch: 273 - Train_loss: 0.74973 - Train_acc: 0.99389 - Val_loss: 0.75410 - Val_acc: 0.989715 - T_Time: 8.498\n",
      "- Epoch: 274 - Train_loss: 0.75019 - Train_acc: 0.99340 - Val_loss: 0.75515 - Val_acc: 0.988232 - T_Time: 8.484\n",
      "- Epoch: 275 - Train_loss: 0.74982 - Train_acc: 0.99386 - Val_loss: 0.75349 - Val_acc: 0.990210 - T_Time: 8.540\n",
      "- Epoch: 276 - Train_loss: 0.74978 - Train_acc: 0.99387 - Val_loss: 0.75439 - Val_acc: 0.989320 - T_Time: 8.493\n",
      "- Epoch: 277 - Train_loss: 0.74969 - Train_acc: 0.99397 - Val_loss: 0.75456 - Val_acc: 0.989122 - T_Time: 8.483\n",
      "- Epoch: 278 - Train_loss: 0.74961 - Train_acc: 0.99406 - Val_loss: 0.75359 - Val_acc: 0.990210 - T_Time: 8.481\n",
      "- Epoch: 279 - Train_loss: 0.74987 - Train_acc: 0.99377 - Val_loss: 0.75445 - Val_acc: 0.989023 - T_Time: 8.504\n",
      "- Epoch: 280 - Train_loss: 0.75012 - Train_acc: 0.99354 - Val_loss: 0.75361 - Val_acc: 0.990111 - T_Time: 8.443\n",
      "- Epoch: 281 - Train_loss: 0.74972 - Train_acc: 0.99393 - Val_loss: 0.75488 - Val_acc: 0.988430 - T_Time: 8.473\n",
      "- Epoch: 282 - Train_loss: 0.74968 - Train_acc: 0.99399 - Val_loss: 0.75330 - Val_acc: 0.990407 - T_Time: 8.490\n",
      "Find better model in Epoch 282, saving model.\n",
      "- Epoch: 283 - Train_loss: 0.74967 - Train_acc: 0.99399 - Val_loss: 0.75447 - Val_acc: 0.989122 - T_Time: 8.423\n",
      "- Epoch: 284 - Train_loss: 0.74981 - Train_acc: 0.99392 - Val_loss: 0.75538 - Val_acc: 0.988133 - T_Time: 8.517\n",
      "- Epoch: 285 - Train_loss: 0.74989 - Train_acc: 0.99374 - Val_loss: 0.75424 - Val_acc: 0.989320 - T_Time: 8.479\n",
      "- Epoch: 286 - Train_loss: 0.74987 - Train_acc: 0.99378 - Val_loss: 0.75522 - Val_acc: 0.988331 - T_Time: 8.535\n",
      "- Epoch: 287 - Train_loss: 0.74978 - Train_acc: 0.99389 - Val_loss: 0.75339 - Val_acc: 0.990210 - T_Time: 8.566\n",
      "- Epoch: 288 - Train_loss: 0.74978 - Train_acc: 0.99385 - Val_loss: 0.75460 - Val_acc: 0.988924 - T_Time: 8.552\n",
      "- Epoch: 289 - Train_loss: 0.74983 - Train_acc: 0.99383 - Val_loss: 0.75448 - Val_acc: 0.989023 - T_Time: 8.546\n",
      "- Epoch: 290 - Train_loss: 0.74969 - Train_acc: 0.99394 - Val_loss: 0.75483 - Val_acc: 0.988924 - T_Time: 8.535\n",
      "- Epoch: 291 - Train_loss: 0.74961 - Train_acc: 0.99407 - Val_loss: 0.75331 - Val_acc: 0.990210 - T_Time: 8.619\n",
      "- Epoch: 292 - Train_loss: 0.74971 - Train_acc: 0.99399 - Val_loss: 0.75399 - Val_acc: 0.989913 - T_Time: 8.457\n",
      "- Epoch: 293 - Train_loss: 0.74988 - Train_acc: 0.99374 - Val_loss: 0.75445 - Val_acc: 0.988924 - T_Time: 8.493\n",
      "- Epoch: 294 - Train_loss: 0.74983 - Train_acc: 0.99383 - Val_loss: 0.75384 - Val_acc: 0.989616 - T_Time: 8.560\n",
      "- Epoch: 295 - Train_loss: 0.74984 - Train_acc: 0.99383 - Val_loss: 0.75472 - Val_acc: 0.988825 - T_Time: 8.475\n",
      "- Epoch: 296 - Train_loss: 0.74972 - Train_acc: 0.99391 - Val_loss: 0.75389 - Val_acc: 0.989715 - T_Time: 8.543\n",
      "- Epoch: 297 - Train_loss: 0.74965 - Train_acc: 0.99403 - Val_loss: 0.75430 - Val_acc: 0.989419 - T_Time: 8.522\n",
      "- Epoch: 298 - Train_loss: 0.74986 - Train_acc: 0.99380 - Val_loss: 0.75514 - Val_acc: 0.988034 - T_Time: 8.447\n",
      "- Epoch: 299 - Train_loss: 0.74997 - Train_acc: 0.99365 - Val_loss: 0.75412 - Val_acc: 0.989419 - T_Time: 8.445\n",
      "Training Finished\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from train_model import *\n",
    "from test_model import *\n",
    "import time\n",
    "\n",
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "best_loss = 3\n",
    "model.to(device)\n",
    "        \n",
    "for epoch in range(1,201):\n",
    "    time_all=0\n",
    "    start_time = time.time()\n",
    "    train_loss,train_acc = train_model(train_loader, model, criterion, optimizer,device)\n",
    "    time_all = time.time()-start_time\n",
    "    valid_loss,valid_acc = test_model(valid_loader,criterion,model,device)\n",
    "    print('- Epoch: %d - Train_loss: %.5f - Train_acc: %.5f - Val_loss: %.5f - Val_acc: %5f - T_Time: %.3f' %(epoch,train_loss,train_acc,valid_loss,valid_acc,time_all))\n",
    "\n",
    "    try:                                         \n",
    "        vis.line(\n",
    "                X = [epoch],\n",
    "                Y = [[train_loss,valid_loss]],\n",
    "                win = loss_curve,\n",
    "                update='append'\n",
    "                )    \n",
    "    except:\n",
    "        print('visdom error......')\n",
    "\n",
    "    try:                                       \n",
    "        vis.line(\n",
    "                X = [epoch],\n",
    "                Y = [[train_acc,valid_acc]],\n",
    "                win = acc_curve,\n",
    "                update='append'\n",
    "                )      \n",
    "    except:\n",
    "        print('visdom error......')\n",
    "\n",
    "        \n",
    "    if valid_loss < best_loss:\n",
    "        best_loss = valid_loss\n",
    "        print('Find better model in Epoch {0}, saving model.'.format(epoch))\n",
    "        torch.save(model.state_dict(), './best_model.pt')\n",
    "\n",
    "print('Training Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 1; 11.00 GiB total capacity; 8.39 GiB already allocated; 3.17 MiB free; 8.51 GiB reserved in total by PyTorch)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-2cdf562fcfc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtest_sum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_model_for_ali\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_sum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\yurui\\Desktop\\item\\heart\\code\\test_model_for_ali.py\u001b[0m in \u001b[0;36mtest_model_for_ali\u001b[1;34m(test_loader, model, device)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0msums\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\yus_pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-82b8c87bde89>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\yus_pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\yus_pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\yus_pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    258\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m    259\u001b[0m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[1;32m--> 260\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 1; 11.00 GiB total capacity; 8.39 GiB already allocated; 3.17 MiB free; 8.51 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "from test_model_for_ali import test_model_for_ali\n",
    "import torch\n",
    "\n",
    "model = CNN()\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "model.eval()\n",
    "\n",
    "test_sum,test_acc = test_model_for_ali(test_loader,model,device)\n",
    "print(test_sum)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-b66b6765de33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mipath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'C:\\\\Users\\\\yurui\\\\Desktop\\\\item\\\\heart\\\\data'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from filter import filter\n",
    "\n",
    "ipath = 'C:\\\\Users\\\\yurui\\\\Desktop\\\\item\\\\heart\\\\data'\n",
    "opath = 'C:\\\\Users\\\\yurui\\\\Desktop\\\\item\\\\heart\\\\output'\n",
    "signal = []\n",
    "\n",
    "with open(os.path.join(ipath,'testA.csv'),'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for line in reader:\n",
    "        signal.append(filter([float(num) for num in line['heartbeat_signals'].split(',')]))\n",
    "\n",
    "\n",
    "result = od.read_csv(os.path.join(ipath,'sample_submit.csv'))\n",
    "result['label_0'] = res[0]\n",
    "result['label_1'] = res[1]\n",
    "result['label_2'] = res[2]\n",
    "result['label_3'] = res[3]\n",
    "result.to_csv(os.path.join(opath,'sample_submit.csv'),index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}